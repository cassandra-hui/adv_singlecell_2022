# Ideas for "Combining the best of two worlds: Python and R"

## Combined analysis using separated steps

- workflow tools (make, Snakemake, knime, custom pipelines, ...)
- pro: flexible, can combine any tool (scripts, binaries, ...)
- contra: no real integration, need for cut-and-glue code (e.g. exporting/reformatting/importing intermediate results)

## Calling one language from the other

- made possible by "bridge" packages/modules
  * reticulate (python from R)
  * rpy2 (R from python)
- pro: easy to use (primarly use one language)
- contra: indirect access to one world, need to learn bridge package syntax

## Combined analysis using an Rmarkdown notebook

- other alternative: Emacs org-mode, Beaker notebook (not developped anymore), ...
- Rmarkdown notebook: (markdown + R/python/... code) * knitr = html
- RStudio as editor
- see also: https://blog.rstudio.com/2018/03/26/reticulate-r-interface-to-python/

## Combined analysis using an Jupyter notebook

- see also: https://ipython.org/ipython-doc/2/config/extensions/rmagic.html
  or better: https://rpy2.github.io/doc/latest/html/interactive.html#module-rpy2.ipython.rmagic
- usage (%R -> line, %%R -> cell):
  %R [-i INPUT] [-o OUTPUT] [-w WIDTH] [-h HEIGHT] [-d DATAFRAME]
       [-u {px,in,cm,mm}] [-r RES] [-p POINTSIZE] [-b BG] [-n]
       [code [code ...]]
  %Rpush
  %Rpull
- example:
cell1:
# enables the %%R magic, not necessary if you've already done this
%load_ext rpy2.ipython

import pandas as pd
df = pd.DataFrame({
    'cups_of_coffee': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
    'productivity': [2, 5, 6, 8, 9, 8, 0, 1, 0, -1]
})

cell2:
%%R -i df -w 5 -h 5 --units in -r 200
# import df from global environment
# make default figure size 5 by 5 inches with 200 dpi resolution

library(ggplot2)
ggplot(df, aes(x=cups_of_coffee, y=productivity)) + geom_line()

cell3:
%%R
pkgs <- c("batchelor", "Biostrings", "BSgenome", "dplyr", "eisaR",
          "GenomeInfoDb", "GenomeInfoDbData", "GenomicFeatures", "GenomicRanges",
          "ggplot2", "IRanges", "keras", "knitr", "reticulate", "rjson", "rmarkdown",
          "scater", "scran", "Seurat", "SingleCellExperiment", "SummarizedExperiment",
          "tensorflow", "tibble", "tidyr", "tximeta")
ipkgs <- rownames(installed.packages())
all(pkgs %in% ipkgs)

cell4:
%%R -o df2
df2 <- installed.packages()

cell5:
df2



# Important topics to also discuss

## A word of caution on the use of notebooks:
- presentation by Joel Grus at JupyterCon 2018:
  https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/edit#slide=id.g362da58057_0_1
  (slides are on Jupyter notebooks, but applies equally to RStudio notebooks)
- in a nutshell:
   * possible to run chunks out of order and to have an inconsistent state (shown output is not what you would get upon rerun)
   * the hidden state makes it difficult to understand what's going on
   * it's hard to write modular code with unit tests in notebooks
   * better: use markdown (compile -> in order, no bad surprises)


## Copying of objects (pass-by-value vs. pass-by-reference)
- see: https://rpy2.github.io/doc/latest/html/rinterface.html#pass-by-value-paradigm

## Pitfall "object indexing": Python 0..n-1, R 1..n

## dplyr in python: 
- see: https://rpy2.github.io/doc/latest/html/lib_dplyr.html

## Comparison: ggplot2 through rpy2 vs. ggplot2 through %%R block in Jupyter notebook


# usage examples
- pass objects of certain classes from R/python to python/R
  * numpy array
     X = np.array([4.5,6.3,7.9])
     X.mean()
     %Rpush X
     %R mean(X)

  * sparse matrix (R, python)
  * data frame (R, python) -> special support for R's data.frame <-> python's pandas.DataFrame

  * use a python function in R
  # Define a python function, and make
# it a function R can use through `rternalize`
from rpy2.rinterface import rternalize
@rternalize
def mean_np(x):
    import statistics
    return statistics.mean(x)

# Bind that function to a symbol in R's
# global environment
from rpy2.robjects import globalenv
globalenv['mean_np'] = mean_np

# Write a dplyr chain of operations,
# using our Python function `mean_np`
dataf = (DataFrame(mtcars).
         filter('gear>3').
         mutate(powertoweight='hp*36/wt').
         group_by('gear').
         summarize(mean_ptw='mean(powertoweight)',
                   mean_np_ptw='mean_np(powertoweight)'))

dataf

  * use an R function in python
  
- use python to process data, plot in R ggplot2
- use PyTorch from R
- performance?
